import os
import shutil
import subprocess
import sys
import yaml

from ansible_waldur_generator.helpers import ValidationErrorCollector
from ansible_waldur_generator.plugin_manager import PluginManager
from .api_parser import ApiSpecParser


GENERIC_MODULE_TEMPLATE = """#!/usr/bin/python
#
# THIS FILE IS AUTOGENERATED BY THE ANSIBLE MODULE GENERATOR - DO NOT EDIT
#
from ansible.module_utils.basic import AnsibleModule
from {runner_import_path} import {runner_class_name}
{sdk_imports}

ANSIBLE_METADATA = {{
    "metadata_version": "1.1",
    "status": ["preview"],
    "supported_by": "OpenNode",
}}

DOCUMENTATION = \"\"\"
---
{documentation_yaml}
\"\"\"

EXAMPLES = \"\"\"
{examples_yaml}
\"\"\"

RETURN = \"\"\"
{return_yaml}
\"\"\"

ARGUMENT_SPEC = {argument_spec_string}

RUNNER_CONTEXT = {runner_context_string}


def main():
    \"\"\"Main execution entrypoint for the Ansible module.\"\"\"
    module = AnsibleModule(
        argument_spec=ARGUMENT_SPEC,
        supports_check_mode=True,
    )
    runner = {runner_class_name}(module, RUNNER_CONTEXT)
    runner.run()


if __name__ == '__main__':
    main()
"""


class Generator:
    """
    Orchestrates the Ansible module generation process. It reads configuration,
    parses an OpenAPI specification, and uses a plugin-based system to generate
    a self-contained Ansible Collection.
    """

    def __init__(self, config_data, api_spec_data):
        """
        Initializes the generator.

        Args:
            config_data (dict): The parsed generator_config.yaml data.
            api_spec_data (dict): The parsed waldur_api.yaml (OpenAPI) data.
        """
        self.config_data = config_data
        self.api_spec_data = api_spec_data
        self.plugin_manager = PluginManager()
        # A set to track which runners have been copied to avoid redundant file I/O.
        self.copied_runners = set()

        # Read collection info from the config, with sane defaults.
        collection_config = self.config_data.get("collection", {})
        self.collection_namespace = collection_config.get("namespace", "community")
        self.collection_name = collection_config.get("name", "generic")
        self.collection_version = collection_config.get("version", "1.0.0")

    @classmethod
    def from_files(cls, config_path, api_spec_path):
        """
        A convenience factory method to create a Generator instance by loading
        configuration and spec from file paths. This is the typical entry point.
        """
        try:
            with open(config_path, "r") as f:
                config_data = yaml.safe_load(f)
        except (IOError, yaml.YAMLError) as e:
            print(
                f"Error reading or parsing config file '{config_path}': {e}",
                file=sys.stderr,
            )
            sys.exit(1)
        try:
            with open(api_spec_path, "r") as f:
                api_spec_data = yaml.safe_load(f)
        except (IOError, yaml.YAMLError) as e:
            print(
                f"Error reading or parsing API spec file '{api_spec_path}': {e}",
                file=sys.stderr,
            )
            sys.exit(1)
        return cls(config_data, api_spec_data)

    def _get_collection_root(self, output_dir: str) -> str:
        """
        Returns the root path of the collection, centralizing the path logic.
        Example: .../outputs/ansible_collections/waldur/cloud
        """
        return os.path.join(
            output_dir,
            "ansible_collections",
            self.collection_namespace,
            self.collection_name,
        )

    def _setup_collection_skeleton(self, output_dir: str):
        """
        Creates the basic directory structure and metadata files required for a valid
        Ansible Collection. This is called once at the start of generation.
        """
        collection_root = self._get_collection_root(output_dir)
        plugins_dir = os.path.join(collection_root, "plugins")
        modules_dir = os.path.join(plugins_dir, "modules")
        module_utils_dir = os.path.join(plugins_dir, "module_utils")
        meta_dir = os.path.join(collection_root, "meta")

        # Create all necessary directories. `exist_ok=True` prevents errors on subsequent runs.
        os.makedirs(modules_dir, exist_ok=True)
        os.makedirs(module_utils_dir, exist_ok=True)
        os.makedirs(meta_dir, exist_ok=True)

        # Define the content for galaxy.yml as a Python dictionary for maintainability.
        galaxy_data = {
            "namespace": self.collection_namespace,
            "name": self.collection_name,
            "version": self.collection_version,
            "readme": "README.md",
            "authors": ["Waldur Team <info@waldur.com>"],
            "description": "A collection of Ansible modules for managing Waldur resources, generated automatically.",
            "license": ["MIT"],
            "tags": ["waldur", "cloud", "management", "automation"],
            "dependencies": {},
            "repository": "https://github.com/waldur/ansible-waldur-module-next",
            "documentation": "https://docs.waldur.com/",
            "homepage": "https://waldur.com/",
            "issues": "https://github.com/waldur/ansible-waldur-module-next/issues",
        }

        # Serialize the dictionary to a YAML file.
        with open(os.path.join(collection_root, "galaxy.yml"), "w") as f:
            yaml.dump(galaxy_data, f, sort_keys=False, default_flow_style=False)

        # Create the meta/runtime.yml file.
        # This specifies the minimum Ansible version required to run the collection.
        # '>=2.14' is a safe and modern choice. Ansible 2.9 is very old;
        # modern collections should target more recent versions.
        runtime_data = {
            "requires_ansible": ">=2.14",
        }
        with open(os.path.join(meta_dir, "runtime.yml"), "w") as f:
            yaml.dump(runtime_data, f, sort_keys=False, default_flow_style=False)

        # Create a placeholder README.md for the collection.
        readme_content = (
            f"# Waldur Ansible Collection: {self.collection_namespace}.{self.collection_name}\n\n"
            "This collection is automatically generated by the Waldur Ansible Module Generator.\n\n"
            "## Usage\n\n"
            "Reference modules using their Fully Qualified Collection Name (FQCN), for example: `waldur.cloud.project`.\n"
        )
        with open(os.path.join(collection_root, "README.md"), "w") as f:
            f.write(readme_content)

    def _copy_runner_dependencies(self, plugin, output_dir: str):
        """
        Copies the runner files into the collection's 'module_utils' directory.
        This "vendoring" approach makes the generated modules self-contained.
        """
        plugin_type = plugin.get_type_name()
        if plugin_type in self.copied_runners:
            return  # Avoid redundant copies

        runner_src_path = plugin.get_runner_path()
        if not (runner_src_path and os.path.exists(runner_src_path)):
            return  # This plugin might not use a separate runner file.

        collection_root = self._get_collection_root(output_dir)
        # All our vendored utils live under a 'waldur' subdirectory to avoid name collisions.
        dest_utils_dir = os.path.join(
            collection_root, "plugins", "module_utils", "waldur"
        )
        os.makedirs(dest_utils_dir, exist_ok=True)

        # Ensure the destination directory is a Python package by creating an __init__.py.
        open(os.path.join(dest_utils_dir, "__init__.py"), "a").close()

        # Copy the BaseRunner, as all specific runners depend on it. This is done only once.
        if "base" not in self.copied_runners:
            project_root = os.path.dirname(os.path.dirname(__file__))
            base_runner_src = os.path.join(
                project_root, "ansible_waldur_generator", "interfaces", "runner.py"
            )
            base_runner_dest = os.path.join(dest_utils_dir, "base_runner.py")
            if os.path.exists(base_runner_src):
                shutil.copy(base_runner_src, base_runner_dest)
                self.copied_runners.add("base")

        # Copy the specific runner for the current plugin type (e.g., crud_runner.py).
        runner_dest_path = os.path.join(dest_utils_dir, f"{plugin_type}_runner.py")
        shutil.copy(runner_src_path, runner_dest_path)

        # Rewrite the import statement inside the copied runner to make it self-contained.
        with open(runner_dest_path, "r+") as f:
            content = f.read()

            # Define the correct, fully qualified path to the vendored BaseRunner
            base_runner_fqcn = (
                f"ansible_collections.{self.collection_namespace}.{self.collection_name}"
                f".plugins.module_utils.waldur.base_runner"
            )

            # Replace the generator-internal import with the new FQCN.
            new_content = content.replace(
                "from ansible_waldur_generator.interfaces.runner import BaseRunner",
                f"from {base_runner_fqcn} import BaseRunner",
            )
            f.seek(0)
            f.write(new_content)
            f.truncate()
        self.copied_runners.add(plugin_type)

    def generate(self, output_dir: str):
        """
        Runs the full generation process, creating a self-contained Ansible Collection.
        """
        # Step 1: Set up the basic collection directory structure and metadata files.
        self._setup_collection_skeleton(output_dir)

        collector = ValidationErrorCollector()
        api_parser = ApiSpecParser(self.api_spec_data, collector)
        collector.report()  # Fail fast if the API spec itself is invalid.

        collection_root = self._get_collection_root(output_dir)
        modules_dir = os.path.join(collection_root, "plugins", "modules")
        generated_file_paths = []

        # Step 2: Loop through each module definition in the generator_config.yaml.
        for module_key, raw_config in self.config_data.get("modules", {}).items():
            module_type = raw_config.get("type")
            plugin = self.plugin_manager.get_plugin(module_type)
            if not plugin:
                collector.add_error(
                    f"Module '{module_key}': No plugin found for type '{module_type}'."
                )
                continue

            # Step 3: Copy the necessary runner files for this module type into the collection.
            self._copy_runner_dependencies(plugin, output_dir)

            try:
                # The core workflow: Parse config -> Build context -> Render template.
                parser = plugin.get_parser(
                    module_key, raw_config, api_parser, collector
                )
                module_config = parser.parse()
                if collector.has_errors or not module_config:
                    continue

                builder = plugin.get_builder(module_config, api_parser, collector)
                context_obj = builder.build(
                    collection_namespace=self.collection_namespace,
                    collection_name=self.collection_name,
                )
                context_dict = context_obj.to_dict()

                # Prepare the multi-line sdk_imports string for simple substitution.
                sdk_imports_str = "\n".join(
                    f"from {imp['module']} import {imp['function']}"
                    for imp in context_dict.get("sdk_imports", [])
                )
                context_dict["sdk_imports"] = sdk_imports_str

                # Render the final module code using the inlined Python string template.
                rendered_template = GENERIC_MODULE_TEMPLATE.format(
                    **context_dict,
                    documentation_yaml=yaml.dump(
                        context_dict["documentation"],
                        default_flow_style=False,
                        sort_keys=False,
                        indent=2,
                        width=1000,
                    ),
                    examples_yaml=yaml.dump(
                        context_dict["examples"],
                        default_flow_style=False,
                        sort_keys=False,
                        indent=2,
                        width=1000,
                    ),
                    return_yaml=yaml.dump(
                        context_dict["return_block"],
                        default_flow_style=False,
                        sort_keys=False,
                        indent=2,
                        width=1000,
                    ),
                )

                # Step 4: Write the final module file into the collection's 'modules' directory.
                output_path = os.path.join(modules_dir, f"{module_key}.py")
                with open(output_path, "w") as f:
                    f.write(rendered_template)
                generated_file_paths.append(output_path)
                print(f"Successfully generated module: {output_path}")

            except Exception as e:
                collector.add_error(
                    f"Unexpected error in plugin '{module_type}' on module '{module_key}': {e}"
                )
                import traceback

                traceback.print_exc()

        # Step 5: Format all generated Python files for cleanliness and PEP-8 compliance.
        if generated_file_paths:
            try:
                utils_path = os.path.join(collection_root, "plugins", "module_utils")
                # Format both the newly created modules and the copied utils.
                subprocess.run(
                    ["ruff", "format", modules_dir, utils_path],
                    capture_output=True,
                    text=True,
                    check=True,
                )
            except (subprocess.CalledProcessError, FileNotFoundError) as e:
                print(
                    f"Warning: Could not format generated files with 'ruff'. Is it installed? Error: {e}",
                    file=sys.stderr,
                )

        # Step 6: Report any final errors that were collected during the process.
        collector.report()
