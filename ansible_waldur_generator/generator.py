import os
import pprint
import shutil
import subprocess
import sys
from typing import Any
import yaml

from ansible_waldur_generator.helpers import (
    AUTH_OPTIONS,
    ValidationErrorCollector,
    capitalize_first,
)
from ansible_waldur_generator.interfaces.config import BaseModuleConfig
from ansible_waldur_generator.interfaces.plugin import BasePlugin
from ansible_waldur_generator.models import AnsibleModuleParams
from ansible_waldur_generator.plugin_manager import PluginManager
from .api_parser import ApiSpecParser


GENERIC_MODULE_TEMPLATE = """#!/usr/bin/python
#
# THIS FILE IS AUTOGENERATED BY THE ANSIBLE MODULE GENERATOR - DO NOT EDIT
#
from ansible.module_utils.basic import AnsibleModule
from {runner_import_path} import {runner_class_name}

ANSIBLE_METADATA = {{
    "metadata_version": "1.1",
    "status": ["preview"],
    "supported_by": "OpenNode",
}}

DOCUMENTATION = \"\"\"
---
{documentation}
\"\"\"

EXAMPLES = \"\"\"
{examples}
\"\"\"

RETURN = \"\"\"
{return_block}
\"\"\"

ARGUMENT_SPEC = {argument_spec}

RUNNER_CONTEXT = {runner_context}


def main():
    \"\"\"Main execution entrypoint for the Ansible module.\"\"\"
    module = AnsibleModule(
        argument_spec=ARGUMENT_SPEC,
        supports_check_mode=True,
    )
    runner = {runner_class_name}(module, RUNNER_CONTEXT)
    runner.run()


if __name__ == '__main__':
    main()
"""


class Generator:
    """
    Orchestrates the Ansible module generation process. It reads configuration,
    parses an OpenAPI specification, and uses a plugin-based system to generate
    a self-contained Ansible Collection.
    """

    def __init__(self, config_data, api_spec_data):
        """
        Initializes the generator.

        Args:
            config_data (dict): The parsed generator_config.yaml data.
            api_spec_data (dict): The parsed waldur_api.yaml (OpenAPI) data.
        """
        self.config_data = config_data
        self.api_spec_data = api_spec_data
        self.plugin_manager = PluginManager()
        # A set to track which runners have been copied to avoid redundant file I/O.
        self.copied_runners = set()

        # Read collection info from the config, with sane defaults.
        collection_config = self.config_data.get("collection", {})
        self.collection_namespace = collection_config.get("namespace", "community")
        self.collection_name = collection_config.get("name", "generic")
        self.collection_version = collection_config.get("version", "1.0.0")

    @classmethod
    def from_files(cls, config_path, api_spec_path):
        """
        A convenience factory method to create a Generator instance by loading
        configuration and spec from file paths. This is the typical entry point.
        """
        try:
            with open(config_path, "r") as f:
                config_data = yaml.safe_load(f)
        except (IOError, yaml.YAMLError) as e:
            print(
                f"Error reading or parsing config file '{config_path}': {e}",
                file=sys.stderr,
            )
            sys.exit(1)
        try:
            with open(api_spec_path, "r") as f:
                api_spec_data = yaml.safe_load(f)
        except (IOError, yaml.YAMLError) as e:
            print(
                f"Error reading or parsing API spec file '{api_spec_path}': {e}",
                file=sys.stderr,
            )
            sys.exit(1)
        return cls(config_data, api_spec_data)

    def _get_collection_root(self, output_dir: str) -> str:
        """
        Returns the root path of the collection, centralizing the path logic.
        Example: .../outputs/ansible_collections/waldur/cloud
        """
        return os.path.join(
            output_dir,
            "ansible_collections",
            self.collection_namespace,
            self.collection_name,
        )

    def _setup_collection_skeleton(self, output_dir: str):
        """
        Creates the basic directory structure and metadata files required for a valid
        Ansible Collection. This is called once at the start of generation.
        """
        collection_root = self._get_collection_root(output_dir)
        plugins_dir = os.path.join(collection_root, "plugins")
        modules_dir = os.path.join(plugins_dir, "modules")
        module_utils_dir = os.path.join(plugins_dir, "module_utils")
        meta_dir = os.path.join(collection_root, "meta")

        # Create all necessary directories. `exist_ok=True` prevents errors on subsequent runs.
        os.makedirs(modules_dir, exist_ok=True)
        os.makedirs(module_utils_dir, exist_ok=True)
        os.makedirs(meta_dir, exist_ok=True)

        # Define the content for galaxy.yml as a Python dictionary for maintainability.
        galaxy_data = {
            "namespace": self.collection_namespace,
            "name": self.collection_name,
            "version": self.collection_version,
            "readme": "README.md",
            "authors": ["Waldur Team <info@waldur.com>"],
            "description": "A collection of Ansible modules for managing Waldur resources, generated automatically.",
            "license": ["MIT"],
            "tags": ["waldur", "cloud", "management", "automation"],
            "dependencies": {},
            "repository": "https://github.com/waldur/ansible-waldur-module-next",
            "documentation": "https://docs.waldur.com/",
            "homepage": "https://waldur.com/",
            "issues": "https://github.com/waldur/ansible-waldur-module-next/issues",
        }

        # Serialize the dictionary to a YAML file.
        with open(os.path.join(collection_root, "galaxy.yml"), "w") as f:
            yaml.dump(galaxy_data, f, sort_keys=False, default_flow_style=False)

        # Create the meta/runtime.yml file.
        # This specifies the minimum Ansible version required to run the collection.
        # '>=2.14' is a safe and modern choice. Ansible 2.9 is very old;
        # modern collections should target more recent versions.
        runtime_data = {
            "requires_ansible": ">=2.14",
        }
        with open(os.path.join(meta_dir, "runtime.yml"), "w") as f:
            yaml.dump(runtime_data, f, sort_keys=False, default_flow_style=False)

        # Create a placeholder README.md for the collection.
        readme_content = (
            f"# Waldur Ansible Collection: {self.collection_namespace}.{self.collection_name}\n\n"
            "This collection is automatically generated by the Waldur Ansible Module Generator.\n\n"
            "## Usage\n\n"
            "Reference modules using their Fully Qualified Collection Name (FQCN), for example: `waldur.cloud.project`.\n"
        )
        with open(os.path.join(collection_root, "README.md"), "w") as f:
            f.write(readme_content)

    def _copy_runner_dependencies(self, plugin, output_dir: str):
        """
        Copies the runner files into the collection's 'module_utils' directory.
        This "vendoring" approach makes the generated modules self-contained.
        """
        plugin_type = plugin.get_type_name()
        if plugin_type in self.copied_runners:
            return  # Avoid redundant copies

        runner_src_path = plugin.get_runner_path()
        if not (runner_src_path and os.path.exists(runner_src_path)):
            return  # This plugin might not use a separate runner file.

        collection_root = self._get_collection_root(output_dir)
        # All our vendored utils live under a 'waldur' subdirectory to avoid name collisions.
        dest_utils_dir = os.path.join(
            collection_root, "plugins", "module_utils", "waldur"
        )
        os.makedirs(dest_utils_dir, exist_ok=True)

        # Ensure the destination directory is a Python package by creating an __init__.py.
        open(os.path.join(dest_utils_dir, "__init__.py"), "a").close()

        # Copy the BaseRunner, as all specific runners depend on it. This is done only once.
        if "base" not in self.copied_runners:
            project_root = os.path.dirname(os.path.dirname(__file__))
            base_runner_src = os.path.join(
                project_root, "ansible_waldur_generator", "interfaces", "runner.py"
            )
            base_runner_dest = os.path.join(dest_utils_dir, "base_runner.py")
            if os.path.exists(base_runner_src):
                shutil.copy(base_runner_src, base_runner_dest)
                self.copied_runners.add("base")

        # Copy the specific runner for the current plugin type (e.g., crud_runner.py).
        runner_dest_path = os.path.join(dest_utils_dir, f"{plugin_type}_runner.py")
        shutil.copy(runner_src_path, runner_dest_path)

        # Rewrite the import statement inside the copied runner to make it self-contained.
        with open(runner_dest_path, "r+") as f:
            content = f.read()

            # Define the correct, fully qualified path to the vendored BaseRunner
            base_runner_fqcn = (
                f"ansible_collections.{self.collection_namespace}.{self.collection_name}"
                f".plugins.module_utils.waldur.base_runner"
            )

            # Replace the generator-internal import with the new FQCN.
            new_content = content.replace(
                "from ansible_waldur_generator.interfaces.runner import BaseRunner",
                f"from {base_runner_fqcn} import BaseRunner",
            )
            f.seek(0)
            f.write(new_content)
            f.truncate()
        self.copied_runners.add(plugin_type)

    def generate(self, output_dir: str):
        """
        Runs the full generation process, creating a self-contained Ansible Collection.
        """
        # Step 1: Set up the basic collection directory structure and metadata files.
        self._setup_collection_skeleton(output_dir)

        collector = ValidationErrorCollector()
        api_parser = ApiSpecParser(self.api_spec_data, collector)
        collector.report()  # Fail fast if the API spec itself is invalid.

        collection_root = self._get_collection_root(output_dir)
        modules_dir = os.path.join(collection_root, "plugins", "modules")
        generated_file_paths = []

        # Step 2: Loop through each module definition in the generator_config.yaml.
        for module_key, raw_config in self.config_data.get("modules", {}).items():
            module_type = raw_config.get("type")
            plugin = self.plugin_manager.get_plugin(module_type)
            if not plugin:
                collector.add_error(
                    f"Module '{module_key}': No plugin found for type '{module_type}'."
                )
                continue

            # Step 3: Copy the necessary runner files for this module type into the collection.
            self._copy_runner_dependencies(plugin, output_dir)

            try:
                # The core workflow: Parse config -> Build context -> Render template.
                parser = plugin.get_parser(
                    module_key, raw_config, api_parser, collector
                )
                module_config = parser.parse()
                if collector.has_errors or not module_config:
                    continue

                rendered_template = self.render_template(
                    plugin,
                    module_key,
                    module_config,
                    api_parser,
                    collector,
                )

                # Step 4: Write the final module file into the collection's 'modules' directory.
                output_path = os.path.join(modules_dir, f"{module_key}.py")
                with open(output_path, "w") as f:
                    f.write(rendered_template)
                generated_file_paths.append(output_path)
                print(f"Successfully generated module: {output_path}")

            except Exception as e:
                collector.add_error(
                    f"Unexpected error in plugin '{module_type}' on module '{module_key}': {e}"
                )
                import traceback

                traceback.print_exc()

        # Step 5: Format all generated Python files for cleanliness and PEP-8 compliance.
        if generated_file_paths:
            try:
                utils_path = os.path.join(collection_root, "plugins", "module_utils")
                # Format both the newly created modules and the copied utils.
                subprocess.run(
                    ["ruff", "format", modules_dir, utils_path],
                    capture_output=True,
                    text=True,
                    check=True,
                )
            except (subprocess.CalledProcessError, FileNotFoundError) as e:
                print(
                    f"Warning: Could not format generated files with 'ruff'. Is it installed? Error: {e}",
                    file=sys.stderr,
                )

        # Step 6: Report any final errors that were collected during the process.
        collector.report()

    def render_template(
        self,
        plugin: BasePlugin,
        module_key: str,
        module_config: BaseModuleConfig,
        api_parser: ApiSpecParser,
        collector: ValidationErrorCollector,
    ) -> str:
        builder = plugin.get_builder(module_config, api_parser, collector)
        parameters = builder._build_parameters()
        argument_spec = self._build_argument_spec(parameters)
        documentation = self._build_documentation(
            module_config,
            module_key,
            parameters,
            self.collection_namespace,
            self.collection_name,
        )
        examples = builder._build_examples(
            module_config.module_key,
            parameters,
            self.collection_namespace,
            self.collection_name,
        )
        return_block = builder._build_return_block()

        runner_import_path = (
            f"ansible_collections.{self.collection_namespace}.{self.collection_name}"
            f".plugins.module_utils.waldur.{plugin.get_type_name()}_runner"
        )

        runner_class_name = f"{capitalize_first(plugin.get_type_name())}Runner"

        runner_context = builder._build_runner_context()

        return GENERIC_MODULE_TEMPLATE.format(
            runner_import_path=runner_import_path,
            runner_class_name=runner_class_name,
            documentation=yaml.dump(
                documentation,
                default_flow_style=False,
                sort_keys=False,
                indent=2,
                width=1000,
            ),
            examples=yaml.dump(
                examples,
                default_flow_style=False,
                sort_keys=False,
                indent=2,
                width=1000,
            ),
            return_block=yaml.dump(
                return_block,
                default_flow_style=False,
                sort_keys=False,
                indent=2,
                width=1000,
            ),
            argument_spec=pprint.pformat(
                argument_spec,
                indent=4,
                width=120,
                sort_dicts=False,
            ),
            runner_context=pprint.pformat(
                runner_context,
                indent=4,
                width=120,
                sort_dicts=False,
            ),
        )

    def _build_documentation(
        self,
        module_config: BaseModuleConfig,
        module_name: str,
        parameters: AnsibleModuleParams,
        collection_namespace: str,
        collection_name: str,
    ) -> dict[str, Any]:
        """Builds the DOCUMENTATION block as a Python dictionary."""
        fqcn = f"{collection_namespace}.{collection_name}.{module_name}"
        doc = {
            "module": fqcn,
            "short_description": module_config.description,
            "version_added": "0.1",
            "description": [module_config.description],
            "requirements": ["python = 3.11"],
            "options": {},
        }
        doc["options"].update({**AUTH_OPTIONS})
        for name, opts in parameters.items():
            doc_data = {
                k: v
                for k, v in opts.items()
                if k in ["description", "required", "type", "choices"] and v is not None
            }
            if "required" not in doc_data:
                doc_data["required"] = False
            doc["options"][name] = doc_data
        return doc

    def _build_argument_spec(self, parameters: AnsibleModuleParams) -> dict:
        """Constructs the full 'argument_spec' dictionary for AnsibleModule."""
        spec = {}
        for name, opts in parameters.items():
            param_spec = {"type": opts["type"], "required": opts.get("required", False)}
            if "choices" in opts:
                param_spec["choices"] = opts["choices"]
            spec[name] = param_spec
        return spec
