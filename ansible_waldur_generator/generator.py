import os
import pprint
import shutil
import subprocess
import sys
import yaml

from ansible_waldur_generator.helpers import (
    ValidationErrorCollector,
    capitalize_first,
)
from ansible_waldur_generator.plugin_manager import PluginManager
from .api_parser import ApiSpecParser
from .schema_parser import ReturnBlockGenerator


GENERIC_MODULE_TEMPLATE = """#!/usr/bin/python
#
# THIS FILE IS AUTOGENERATED BY THE ANSIBLE MODULE GENERATOR - DO NOT EDIT
#
from ansible.module_utils.basic import AnsibleModule
from {runner_import_path} import {runner_class_name}

ANSIBLE_METADATA = {{
    "metadata_version": "1.1",
    "status": ["preview"],
    "supported_by": "OpenNode",
}}

DOCUMENTATION = \"\"\"
---
{documentation}
\"\"\"

EXAMPLES = \"\"\"
{examples}
\"\"\"

RETURN = \"\"\"
{return_block}
\"\"\"

ARGUMENT_SPEC = {argument_spec}

RUNNER_CONTEXT = {runner_context}


def main():
    \"\"\"Main execution entrypoint for the Ansible module.\"\"\"
    module = AnsibleModule(
        argument_spec=ARGUMENT_SPEC,
        supports_check_mode=True,
    )
    runner = {runner_class_name}(module, RUNNER_CONTEXT)
    runner.run()


if __name__ == '__main__':
    main()
"""


class Generator:
    """
    Orchestrates the Ansible module generation process. It reads configuration,
    parses an OpenAPI specification, and uses a plugin-based system to generate
    one or more self-contained Ansible Collections.
    """

    def __init__(self, config_data, api_spec_data):
        """
        Initializes the generator.

        Args:
            config_data (dict): The parsed generator_config.yaml data.
            api_spec_data (dict): The parsed waldur_api.yaml (OpenAPI) data.
        """
        self.config_data = config_data
        self.api_spec_data = api_spec_data
        self.plugin_manager = PluginManager()
        # A set to track which runners have been copied to avoid redundant file I/O.
        self.copied_runners = set()

        # Read collection info from the config, with sane defaults.
        self.collection_namespace = ""
        self.collection_name = ""
        self.collection_version = ""

    @classmethod
    def from_files(cls, config_path, api_spec_path):
        """
        A convenience factory method to create a Generator instance by loading
        configuration and spec from file paths. This is the typical entry point.
        """
        try:
            with open(config_path, "r") as f:
                config_data = yaml.safe_load(f)
        except (IOError, yaml.YAMLError) as e:
            print(
                f"Error reading or parsing config file '{config_path}': {e}",
                file=sys.stderr,
            )
            sys.exit(1)
        try:
            with open(api_spec_path, "r") as f:
                api_spec_data = yaml.safe_load(f)
        except (IOError, yaml.YAMLError) as e:
            print(
                f"Error reading or parsing API spec file '{api_spec_path}': {e}",
                file=sys.stderr,
            )
            sys.exit(1)
        return cls(config_data, api_spec_data)

    def _get_collection_root(self, output_dir: str) -> str:
        """
        Returns the root path of the collection, centralizing the path logic.
        Example: .../outputs/ansible_collections/waldur/structure
        """
        return os.path.join(
            output_dir,
            "ansible_collections",
            self.collection_namespace,
            self.collection_name,
        )

    def _setup_collection_skeleton(self, output_dir: str):
        """
        Creates the basic directory structure and metadata files required for a valid
        Ansible Collection. This is called once at the start of generation.
        """
        collection_root = self._get_collection_root(output_dir)
        plugins_dir = os.path.join(collection_root, "plugins")
        modules_dir = os.path.join(plugins_dir, "modules")
        module_utils_dir = os.path.join(plugins_dir, "module_utils")
        meta_dir = os.path.join(collection_root, "meta")

        # Create all necessary directories. `exist_ok=True` prevents errors on subsequent runs.
        os.makedirs(modules_dir, exist_ok=True)
        os.makedirs(module_utils_dir, exist_ok=True)
        os.makedirs(meta_dir, exist_ok=True)

        # Define the content for galaxy.yml as a Python dictionary for maintainability.
        galaxy_data = {
            "namespace": self.collection_namespace,
            "name": self.collection_name,
            "version": self.collection_version,
            "readme": "README.md",
            "authors": ["Waldur Team <info@waldur.com>"],
            "description": "A collection of Ansible modules for managing Waldur resources, generated automatically.",
            "license": ["MIT"],
            "tags": ["waldur", "cloud", "management", "automation"],
            "dependencies": {},
            "repository": "https://github.com/waldur/ansible-waldur-module-next",
            "documentation": "https://docs.waldur.com/",
            "homepage": "https://waldur.com/",
            "issues": "https://github.com/waldur/ansible-waldur-module-next/issues",
        }

        # Serialize the dictionary to a YAML file.
        with open(os.path.join(collection_root, "galaxy.yml"), "w") as f:
            yaml.dump(galaxy_data, f, sort_keys=False, default_flow_style=False)

        # Create the meta/runtime.yml file.
        # This specifies the minimum Ansible version required to run the collection.
        # '>=2.14' is a safe and modern choice. Ansible 2.9 is very old;
        # modern collections should target more recent versions.
        runtime_data = {
            "requires_ansible": ">=2.14",
        }
        with open(os.path.join(meta_dir, "runtime.yml"), "w") as f:
            yaml.dump(runtime_data, f, sort_keys=False, default_flow_style=False)

        # Create a placeholder README.md for the collection.
        readme_content = (
            f"# Waldur Ansible Collection: {self.collection_namespace}.{self.collection_name}\n\n"
            "This collection is automatically generated by the Waldur Ansible Module Generator.\n\n"
            "## Usage\n\n"
            "Reference modules using their Fully Qualified Collection Name (FQCN), for example: `waldur.structure.project`.\n"
        )
        with open(os.path.join(collection_root, "README.md"), "w") as f:
            f.write(readme_content)

    def _copy_runner_dependencies(self, plugin, output_dir: str):
        """
        Copies the runner files into the collection's 'module_utils' directory.
        This "vendoring" approach makes the generated modules self-contained.
        """
        plugin_type = plugin.get_type_name()
        if plugin_type in self.copied_runners:
            return  # Avoid redundant copies

        runner_src_path = plugin.get_runner_path()
        if not (runner_src_path and os.path.exists(runner_src_path)):
            return  # This plugin might not use a separate runner file.

        collection_root = self._get_collection_root(output_dir)
        project_root = os.path.dirname(os.path.dirname(__file__))
        # All our vendored utils live under a 'waldur' subdirectory to avoid name collisions.
        dest_utils_dir = os.path.join(
            collection_root, "plugins", "module_utils", "waldur"
        )
        os.makedirs(dest_utils_dir, exist_ok=True)

        # Ensure the destination directory is a Python package by creating an __init__.py.
        open(os.path.join(dest_utils_dir, "__init__.py"), "a").close()

        # --- Define all shared dependencies ---
        # A dictionary mapping the source file name to its new destination name.
        shared_deps = {
            "runner.py": "base_runner.py",
            "resolver.py": "resolver.py",
            "command.py": "command.py",
        }

        for src_name, dest_name in shared_deps.items():
            # Check if this shared dependency has already been copied for this collection.
            if dest_name not in self.copied_runners:
                src_path = os.path.join(
                    project_root, "ansible_waldur_generator", "interfaces", src_name
                )
                dest_path = os.path.join(dest_utils_dir, dest_name)
                if os.path.exists(src_path):
                    shutil.copy(src_path, dest_path)
                    self.copied_runners.add(
                        dest_name
                    )  # Mark as copied for this collection run.

        # Copy the specific runner for the current plugin type (e.g., crud_runner.py).
        runner_dest_path = os.path.join(dest_utils_dir, f"{plugin_type}_runner.py")
        shutil.copy(runner_src_path, runner_dest_path)

        # Rewrite the import statement inside the copied runner to make it self-contained.
        with open(runner_dest_path, "r+") as f:
            content = f.read()

            # Define the correct, fully qualified path to the vendored BaseRunner
            base_runner_fqcn = (
                f"ansible_collections.{self.collection_namespace}.{self.collection_name}"
                f".plugins.module_utils.waldur.base_runner"
            )

            resolver_fqcn = (
                f"ansible_collections.{self.collection_namespace}.{self.collection_name}"
                f".plugins.module_utils.waldur.resolver"
            )

            command_fqcn = f"ansible_collections.{self.collection_namespace}.{self.collection_name}.plugins.module_utils.waldur.command"

            # Replace the generator-internal import with the new FQCN.
            new_content = (
                content.replace(
                    "from ansible_waldur_generator.interfaces.runner import BaseRunner",
                    f"from {base_runner_fqcn} import BaseRunner",
                )
                .replace(
                    "from ansible_waldur_generator.interfaces.resolver import ParameterResolver",
                    f"from {resolver_fqcn} import ParameterResolver",
                )
                .replace(
                    "from ansible_waldur_generator.interfaces.command import",
                    f"from {command_fqcn} import",
                )
            )

            f.seek(0)
            f.write(new_content)
            f.truncate()
        self.copied_runners.add(plugin_type)

    def generate(self, output_dir: str):
        """
        Runs the full generation process, creating self-contained Ansible Collections
        for each definition found in the configuration file.
        """
        # --- Step 1: Initialization (Done Once) ---
        # These components are expensive to initialize and are shared across the
        # generation of all collections. They are created once at the beginning.
        collector = ValidationErrorCollector()
        api_parser = ApiSpecParser(self.api_spec_data, collector)
        return_generator = ReturnBlockGenerator(self.api_spec_data)

        # Perform initial validation of the API spec. If it's invalid,
        # there's no point in proceeding.
        collector.report()

        # --- Step 2: Main Generation Loop for Each Collection ---
        # The core of the multi-collection logic. We iterate through the top-level
        # 'collections' list from the generator_config.yaml.
        collections_config = self.config_data.get("collections")
        if not collections_config:
            collector.add_error(
                "The configuration file must contain a top-level 'collections' list."
            )
            collector.report()

        for collection_config in collections_config:
            # --- 2a. Set the Context for the Current Collection ---
            # Update the generator's instance variables to reflect the collection
            # we are currently building. All helper methods like _get_collection_root
            # and _setup_collection_skeleton rely on these instance variables.
            self.collection_namespace = collection_config.get("namespace", "community")
            self.collection_name = collection_config.get("name", "generic")
            self.collection_version = collection_config.get("version", "1.0.0")

            print(
                f"\n--- Generating Collection: {self.collection_namespace}.{self.collection_name} v{self.collection_version} ---"
            )

            # CRITICAL: Reset the set of copied runners for each new collection.
            # Each collection is self-contained and must have its own copy of the
            # necessary module_utils files. Without this reset, a runner copied
            # for the first collection would not be copied for subsequent ones.
            self.copied_runners = set()

            # --- 2b. Create the Directory Structure for This Collection ---
            self._setup_collection_skeleton(output_dir)

            collection_root = self._get_collection_root(output_dir)
            modules_dir = os.path.join(collection_root, "plugins", "modules")
            generated_file_paths = []

            # --- 2c. Inner Loop to Generate Modules for This Collection ---
            for raw_config in collection_config.get("modules", []):
                module_key = raw_config.get("name")
                if not module_key:
                    collector.add_error(
                        f"In collection '{self.collection_name}', a module entry is missing the 'name' key."
                    )
                    continue

                raw_config.setdefault(
                    "resource_type", module_key.replace("_facts", "").replace("_", " ")
                )

                module_type = raw_config.get("plugin")
                if not module_type:
                    collector.add_error(
                        f"In collection '{self.collection_name}', module '{module_key}' is missing the 'plugin' key."
                    )
                    continue

                plugin = self.plugin_manager.get_plugin(module_type)

                if not plugin:
                    # Add error to the collector but continue, so we can see all
                    # errors from all collections at the end.
                    collector.add_error(
                        f"In collection '{self.collection_name}', module '{module_key}': "
                        f"No plugin found for type '{module_type}'."
                    )
                    continue

                # Copy the plugin-specific runner and the base runner into the
                # current collection's module_utils directory.
                self._copy_runner_dependencies(plugin, output_dir)

                try:
                    # Delegate the core logic of parsing the config and building the
                    # context to the discovered plugin. We pass the current collection's
                    # namespace and name so it can generate correct FQCNs in docs/examples.
                    generation_context = plugin.generate(
                        module_key,
                        raw_config,
                        api_parser,
                        self.collection_namespace,  # Current collection's namespace
                        self.collection_name,  # Current collection's name
                        return_generator,
                    )

                    # Determine the runner's import path and class name based on convention.
                    runner_import_path = (
                        f"ansible_collections.{self.collection_namespace}.{self.collection_name}"
                        f".plugins.module_utils.waldur.{plugin.get_type_name()}_runner"
                    )
                    runner_class_name = (
                        f"{capitalize_first(plugin.get_type_name())}Runner"
                    )

                    # --- 2d. Render and Write the Module File ---
                    # The output path is calculated based on the `modules_dir` of the
                    # current collection, ensuring the file is placed correctly.
                    output_path = os.path.join(
                        modules_dir, generation_context.module_filename
                    )
                    with open(output_path, "w") as f:
                        f.write(
                            GENERIC_MODULE_TEMPLATE.format(
                                runner_import_path=runner_import_path,
                                runner_class_name=runner_class_name,
                                documentation=yaml.dump(
                                    generation_context.documentation,
                                    default_flow_style=False,
                                    sort_keys=False,
                                    indent=2,
                                    width=1000,
                                ),
                                examples=yaml.dump(
                                    generation_context.examples,
                                    default_flow_style=False,
                                    sort_keys=False,
                                    indent=2,
                                    width=1000,
                                ),
                                return_block=yaml.dump(
                                    generation_context.return_block,
                                    default_flow_style=False,
                                    sort_keys=False,
                                    indent=2,
                                    width=1000,
                                ),
                                argument_spec=pprint.pformat(
                                    generation_context.argument_spec,
                                    indent=4,
                                    width=120,
                                    sort_dicts=False,
                                ),
                                runner_context=pprint.pformat(
                                    generation_context.runner_context,
                                    indent=4,
                                    width=120,
                                    sort_dicts=False,
                                ),
                            )
                        )
                    generated_file_paths.append(output_path)
                    print(f"  Successfully generated module: {output_path}")

                except Exception as e:
                    # Catch unexpected errors during a specific module's generation.
                    # Provide a detailed error message including the collection and module context.
                    import traceback

                    collector.add_error(
                        f"Unexpected error in collection '{self.collection_name}', module '{module_key}' (plugin '{module_type}'): {e}"
                    )
                    traceback.print_exc()

            # --- 2e. Format Generated Files for the Current Collection ---
            # After all modules for a collection are generated, format them for
            # PEP-8 compliance and consistent style.
            if generated_file_paths:
                try:
                    utils_path = os.path.join(
                        collection_root, "plugins", "module_utils"
                    )
                    # Format both the newly created modules and the copied utils.
                    subprocess.run(
                        ["ruff", "format", modules_dir, utils_path],
                        capture_output=True,
                        text=True,
                        check=True,
                    )
                except (subprocess.CalledProcessError, FileNotFoundError) as e:
                    print(
                        f"Warning: Could not format files for collection '{self.collection_name}' with 'ruff'. "
                        f"Is it installed? Error: {e}",
                        file=sys.stderr,
                    )

        # --- Step 3: Final Report ---
        # After attempting to generate all collections, report any errors that
        # were accumulated throughout the process.
        print("\nGeneration process finished.")
        collector.report()
